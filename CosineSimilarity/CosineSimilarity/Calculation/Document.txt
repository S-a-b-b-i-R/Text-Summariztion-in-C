Digital text is, at present, a leading non-constructed information resource in web. Text classification (TC) is a crucial and well-proven instrument for organizing these large volumes of digital text information which are widespread and increasing continuously. TC is the task of automatically sorting a set of documents into categories from a predefined set. Automated TC is attractive because it frees organizations from the need of manually handling document bases, which can be too expensive, or simply not feasible given the time constraints of the application or the number of documents involved. So far automated TC has become a research hot spot and put forward a series of related applications, e.g. web classification, personalized news, query recommendation, genre identification, spam filtering, and topic spotting etc. A variety of machine learning approaches have been applied to text categorization, including support vector machine and, k-nearest neighbor, neural network, Bayes model, decision tree, etc. Although such methods have been extensively researched, yet the present automated text classifiers are still with fault and the effectiveness needs improvement. Thus, text categorization is still a major research field.
Artificial neural network is a self-learning model that can implement different algorithms extensively utilized in the field of pattern recognition. Classifiers is not without fault and still needs improvement. The back propagation neural network (BPNN) is a kind of basic supervised network. BPNN has the problems of slow training speed and the likelihood of becoming trapped in a local minimum, which makes it difficult to use in practical applications, especially when the scale of the network is large. More specifically, in the beginning of its training steps, the learning process proceeds very quickly in each epoch and can make rapid progress. However, it slows down in the later stages and becomes so called inertia. Meanwhile, it is easy to enter local minima.